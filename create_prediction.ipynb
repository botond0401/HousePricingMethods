{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from load_data import DataLoader\n",
    "from datetime import date\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # None means show all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:69: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data[col].fillna('NA', inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data['MasVnrArea'].fillna(0, inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data['GarageYrBlt'].fillna(0, inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data[col].fillna(mode, inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:69: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data[col].fillna('NA', inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data['MasVnrArea'].fillna(0, inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data['GarageYrBlt'].fillna(0, inplace=True)\n",
      "c:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\HPP\\HousePricingMethods\\load_data.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.data[col].fillna(mode, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader()\n",
    "dataloader.load_data('data/train.csv')\n",
    "dataloader.preprocess_data()\n",
    "df_train = dataloader.data\n",
    "\n",
    "df_train_target = df_train['SalePrice']\n",
    "df_train = df_train.drop(columns='SalePrice')\n",
    "\n",
    "dataloader.load_data('data/test.csv')\n",
    "dataloader.preprocess_data()\n",
    "df_test = dataloader.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = [col for col in df_train.columns if col not in df_test]\n",
    "df_test[missing_columns] = 0\n",
    "df_test = df_test[df_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Quality_Index'] = df['OverallQual'] + df['OverallCond']\n",
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Total_Rooms'] = df['BedroomAbvGr'] + df['KitchenAbvGr'] + df['TotRmsAbvGrd']\n",
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Lot_Size_per_Room'] = df['LotArea'] / (df['BedroomAbvGr'] + df['KitchenAbvGr'] + df['TotRmsAbvGrd']).replace(0, 1)\n",
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Living_Area_per_Bath'] = df['GrLivArea'] / df['Total_Baths'].replace(0, 1)\n",
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Garage_Area_Ratio'] = df['GarageArea'] / df['Total_Finished_SF'].replace(0, 1)\n",
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Total_Porch_per_Room'] = (df['WoodDeckSF'] + df['OpenPorchSF'] + df['EnclosedPorch'] +\n",
      "C:\\Users\\bokovacs\\AppData\\Local\\Temp\\ipykernel_23160\\151994494.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Quality_Adjusted_Area'] = df['TotalBsmtSF'] * (df['OverallQual'] + df['OverallCond'])\n"
     ]
    }
   ],
   "source": [
    "def create_features_and_clean(df):\n",
    "    df['Age'] = df['YrSold'] - df['YearBuilt']\n",
    "    df['RemodelAge'] = df['YrSold'] - df['YearRemodAdd']\n",
    "    df['Total_Baths'] = df['BsmtFullBath'] + df['BsmtHalfBath'] * 0.5 + df['FullBath'] + df['HalfBath']\n",
    "    df['Total_Finished_SF'] = df['GrLivArea'] + df['TotalBsmtSF']\n",
    "    df['Total_Porch_Area'] = (df['WoodDeckSF'] + df['OpenPorchSF'] + df['EnclosedPorch'] +\n",
    "                               df['3SsnPorch'] + df['ScreenPorch'])\n",
    "    df['Garage_Age'] = df['YrSold'] - df['GarageYrBlt']\n",
    "    df['Quality_Index'] = df['OverallQual'] + df['OverallCond']\n",
    "    df['Total_Rooms'] = df['BedroomAbvGr'] + df['KitchenAbvGr'] + df['TotRmsAbvGrd']\n",
    "\n",
    "    # Create multiplicative features\n",
    "    df['Lot_Size_per_Room'] = df['LotArea'] / (df['BedroomAbvGr'] + df['KitchenAbvGr'] + df['TotRmsAbvGrd']).replace(0, 1)\n",
    "    df['Living_Area_per_Bath'] = df['GrLivArea'] / df['Total_Baths'].replace(0, 1)\n",
    "    df['Garage_Area_Ratio'] = df['GarageArea'] / df['Total_Finished_SF'].replace(0, 1)\n",
    "    df['Total_Porch_per_Room'] = (df['WoodDeckSF'] + df['OpenPorchSF'] + df['EnclosedPorch'] + \n",
    "                                   df['3SsnPorch'] + df['ScreenPorch']) / (df['BedroomAbvGr'] + \n",
    "                                   df['KitchenAbvGr'] + df['TotRmsAbvGrd']).replace(0, 1)\n",
    "    df['Quality_Adjusted_Area'] = df['TotalBsmtSF'] * (df['OverallQual'] + df['OverallCond'])\n",
    "\n",
    "    # Define columns to drop (adjust as necessary)\n",
    "    columns_to_drop = ['YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt']\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Create features for both training and test datasets\n",
    "create_features_and_clean(df_train)\n",
    "create_features_and_clean(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: MSE = 822188137.23\n",
      "Linear Regression: MSE = 38024979125706087965004922880.00\n",
      "Support Vector Regressor: MSE = 7857868970.10\n",
      "K-Neighbors Regressor: MSE = 2184084644.40\n",
      "Gradient Boosting: MSE = 750083279.42\n",
      "AdaBoost: MSE = 1375248103.07\n",
      "XGBoost: MSE = 852645450.30\n",
      "Neural Network: MSE = 6807854310.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SpecProF\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train_target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare a list of models to evaluate, including MLPRegressor\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(100, ), max_iter=1000, random_state=42)  # Adding the neural network\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    results[model_name] = mse\n",
    "\n",
    "# Print out the results\n",
    "for model_name, mse in results.items():\n",
    "    print(f\"{model_name}: MSE = {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Forest:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 1. Fine-tuning Random Forest\n",
    "rf_param_grid = {\n",
    "    'max_depth': [10, 12, 14],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Use tqdm with GridSearchCV\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "\n",
    "# Fit GridSearchCV with tqdm progress bar\n",
    "with tqdm(total=len(rf_param_grid['max_depth']) * len(rf_param_grid['n_estimators']) * len(rf_param_grid['min_samples_split']) * len(rf_param_grid['min_samples_leaf']),\n",
    "            desc=\"Random Forest\") as pbar:\n",
    "    rf_grid_search.fit(df_train, df_train_target)\n",
    "    pbar.update()  # Update after each fit (not necessary since GridSearchCV updates internally)\n",
    "\n",
    "# Print best parameters and best score for Random Forest\n",
    "print(\"Random Forest Best Parameters:\", rf_grid_search.best_params_)\n",
    "print(\"Random Forest Best CV Score (neg_mean_squared_error):\", rf_grid_search.best_score_)\n",
    "\n",
    "# Get the best Random Forest model\n",
    "best_model1 = rf_grid_search.best_estimator_\n",
    "\n",
    "# 2. Fine-tuning Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Use tqdm with GridSearchCV\n",
    "gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "\n",
    "# Fit GridSearchCV with tqdm progress bar\n",
    "with tqdm(total=len(gb_param_grid['n_estimators']) * len(gb_param_grid['max_depth']) * len(gb_param_grid['learning_rate']) * len(gb_param_grid['min_samples_split']),\n",
    "            desc=\"Gradient Boosting\") as pbar:\n",
    "    gb_grid_search.fit(df_train, df_train_target)\n",
    "    pbar.update()\n",
    "\n",
    "# Print best parameters and best score for Gradient Boosting\n",
    "print(\"Gradient Boosting Best Parameters:\", gb_grid_search.best_params_)\n",
    "print(\"Gradient Boosting Best CV Score (neg_mean_squared_error):\", gb_grid_search.best_score_)\n",
    "\n",
    "# Get the best Gradient Boosting model\n",
    "best_model2 = gb_grid_search.best_estimator_\n",
    "\n",
    "# 3. Fine-tuning XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Use tqdm with GridSearchCV\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "\n",
    "# Fit GridSearchCV with tqdm progress bar\n",
    "with tqdm(total=len(xgb_param_grid['n_estimators']) * len(xgb_param_grid['max_depth']) * len(xgb_param_grid['learning_rate']) * len(xgb_param_grid['subsample']),\n",
    "            desc=\"XGBoost\") as pbar:\n",
    "    xgb_grid_search.fit(df_train, df_train_target)\n",
    "    pbar.update()\n",
    "\n",
    "# Print best parameters and best score for XGBoost\n",
    "print(\"XGBoost Best Parameters:\", xgb_grid_search.best_params_)\n",
    "print(\"XGBoost Best CV Score (neg_mean_squared_error):\", xgb_grid_search.best_score_)\n",
    "\n",
    "# Get the best XGBoost model\n",
    "best_model3 = xgb_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with each of the best models\n",
    "y_pred1 = best_model1.predict(df_test)\n",
    "y_pred2 = best_model2.predict(df_test)\n",
    "y_pred3 = best_model3.predict(df_test)\n",
    "\n",
    "# Average the predictions\n",
    "y_pred_avg = (y_pred1 + y_pred2 + y_pred3) / 3\n",
    "\n",
    "# Create the DataFrame for submission\n",
    "df_guess = pd.DataFrame(y_pred_avg, columns=['SalePrice'])\n",
    "df_guess['Id'] = range(1461, 2920)  # Adjust the range according to your test set ID\n",
    "df_guess = df_guess[['Id', 'SalePrice']]\n",
    "\n",
    "# Get today's date\n",
    "today = date.today()\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "df_guess.to_csv(f'predictions/prediction_{today}.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
